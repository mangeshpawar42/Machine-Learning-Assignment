{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hodSpTaVUOtd35cSgNWrvJscFcqcD6sl","timestamp":1682674372883}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93EHigroH8Gx","executionInfo":{"status":"ok","timestamp":1682673140401,"user_tz":-330,"elapsed":3469,"user":{"displayName":"TY_B_14_Rahul Choubey","userId":"16670125581561583365"}},"outputId":"ea002742-0a95-4560-87d5-7776496b62a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Single word based sentiment analysis using unigram approach:\n","'I love spending time with my family' is positive\n","\n","\n","'The food was delicious but the service was terrible' is negative\n","\n","\n","'The movie was great, I enjoyed it a lot' is positive\n","\n","\n","'I hate it when it rains all day' is negative\n","\n","\n","'The concert was a disaster, I couldn't stand it' is negative\n","\n","\n","Multiword based sentiment analysis using bi-gram approach:\n","'I love spending time with my family' is positive\n","\n","\n","'The food was delicious but the service was terrible' is positive\n","\n","\n","'The movie was great, I enjoyed it a lot' is positive\n","\n","\n","'I hate it when it rains all day' is negative\n","\n","\n","'The concert was a disaster, I couldn't stand it' is negative\n","\n","\n","Single word based sentiment analysis using unigram approach after negative marking:\n","'I love spending time with my family' is positive\n","\n","\n","'The food was delicious but the service was not_terrible' is positive\n","\n","\n","'The movie was great, I enjoyed it a lot' is positive\n","\n","\n","'I not_hate it when it rains all day' is neutral\n","\n","\n","'The concert was a disaster, I not_couldn't not_stand it' is negative\n","\n","\n","Multiword based sentiment analysis using bi-gram approach after negative marking:\n","'I love spending time with my family' is positive\n","\n","\n","'The food was delicious but the service was not_terrible' is positive\n","\n","\n","'The movie was great, I enjoyed it a lot' is positive\n","\n","\n","'I not_hate it when it rains all day' is neutral\n","\n","\n","'The concert was a disaster, I not_couldn't not_stand it' is negative\n","\n","\n"]}],"source":["import nltk\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","\n","sentences = [\n","    \"I love spending time with my family\",\n","    \"The food was delicious but the service was terrible\",\n","    \"The movie was great, I enjoyed it a lot\",\n","    \"I hate it when it rains all day\",\n","    \"The concert was a disaster, I couldn't stand it\"\n","]\n","\n","\n","sia = SentimentIntensityAnalyzer()\n","\n","\n","def apply_negative_marking(sentences):\n","    new_sentences = []\n","    for sentence in sentences:\n","        words = sentence.split()\n","        new_words = []\n","        for word in words:\n","            if word in [\"hate\", \"terrible\", \"disaster\", \"couldn't\", \"stand\"]:\n","                new_words.append(\"not_\" + word)\n","            else:\n","                new_words.append(word)\n","        new_sentence = \" \".join(new_words)\n","        new_sentences.append(new_sentence)\n","    return new_sentences\n","\n","\n","print(\"Single word based sentiment analysis using unigram approach:\")\n","for sentence in sentences:\n","    sentiment_score = sia.polarity_scores(sentence)\n","    if sentiment_score[\"compound\"] > 0:\n","        print(f\"'{sentence}' is positive\")\n","    elif sentiment_score[\"compound\"] < 0:\n","        print(f\"'{sentence}' is negative\")\n","    else:\n","        print(f\"'{sentence}' is neutral\")\n","    print(\"\\n\")\n","\n","\n","print(\"Multiword based sentiment analysis using bi-gram approach:\")\n","for sentence in sentences:\n","    tokens = nltk.word_tokenize(sentence)\n","    bigrams = list(nltk.bigrams(tokens))\n","    sentiment_score = 0\n","    for bigram in bigrams:\n","        bigram_score = sia.polarity_scores(\" \".join(bigram))\n","        sentiment_score += bigram_score[\"compound\"]\n","    if sentiment_score > 0:\n","        print(f\"'{sentence}' is positive\")\n","    elif sentiment_score < 0:\n","        print(f\"'{sentence}' is negative\")\n","    else:\n","        print(f\"'{sentence}' is neutral\")\n","    print(\"\\n\")\n","\n","\n","\n","negative_marked_sentences = apply_negative_marking(sentences)\n","\n","\n","print(\"Single word based sentiment analysis using unigram approach after negative marking:\")\n","for sentence in negative_marked_sentences:\n","    sentiment_score = sia.polarity_scores(sentence)\n","    if sentiment_score[\"compound\"] > 0:\n","        print(f\"'{sentence}' is positive\")\n","    elif sentiment_score[\"compound\"] < 0:\n","        print(f\"'{sentence}' is negative\")\n","    else:\n","        print(f\"'{sentence}' is neutral\")\n","    print(\"\\n\")\n","\n","\n","print(\"Multiword based sentiment analysis using bi-gram approach after negative marking:\")\n","for sentence in negative_marked_sentences:\n","    tokens = nltk.word_tokenize(sentence)\n","    bigrams = list(nltk.bigrams(tokens))\n","    sentiment_score = 0\n","    for bigram in bigrams:\n","        bigram_score = sia.polarity_scores(\" \".join(bigram))\n","        sentiment_score += bigram_score[\"compound\"]\n","    if sentiment_score > 0:\n","        print(f\"'{sentence}' is positive\")\n","    elif sentiment_score < 0:\n","        print(f\"'{sentence}' is negative\")\n","    else:\n","        print(f\"'{sentence}' is neutral\")\n","    print(\"\\n\")"]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyKLaNMQIi83","executionInfo":{"status":"ok","timestamp":1682673123424,"user_tz":-330,"elapsed":853,"user":{"displayName":"TY_B_14_Rahul Choubey","userId":"16670125581561583365"}},"outputId":"66c2edcc-4b5c-4bec-8ae4-c60471dbff4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":[" nltk.download('vader_lexicon')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkxqe0XYIXch","executionInfo":{"status":"ok","timestamp":1682673090425,"user_tz":-330,"elapsed":15,"user":{"displayName":"TY_B_14_Rahul Choubey","userId":"16670125581561583365"}},"outputId":"46c6121d-f604-4eab-844f-a7898b27d7e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]}]}